{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch.utils.data as D\nimport cv2\nfrom PIL import Image\nfrom torchvision import transforms,models,datasets\nfrom fastai.vision import *\n\ntransform = transforms.Compose([\n                                transforms.CenterCrop(10),\n                                transforms.Resize(224),\n                                transforms.RandomHorizontalFlip(),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean=[0.485],\n                                 std=[0.229])\n])\ntrainset = datasets.ImageFolder(root='/kaggle/input/special5/spl5/',transform=transform)\nprint(len(trainset.classes))\nclassesDict = {idx:i for idx,i in enumerate(trainset.classes)}\npath = '/kaggle/input/special5/'\niB = ImageDataBunch.from_folder(path=path,\n                   train = 'spl5',\n                   seed = 42,\n                   valid_pct = 0.2,\n                   size=224,\n                    bs=32,\n                   ds_tfms=get_transforms(do_flip=True,\n                                      max_warp=0,\n                                      max_rotate=0,\n                                      max_lighting=0,\n                                      p_affine=0,\n                                      xtra_tfms=[crop_pad()]))\nprint(iB)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nlearn3 = cnn_learner(data=iB,base_arch=models.densenet201,model_dir='/tmp/models',metrics=[accuracy])\nmod = learn3.model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data.sampler import SubsetRandomSampler\nimport numpy as np\nimport torch\nlearn3.lr_find()\nlearn3.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn3.unfreeze()\nlearn3.fit_one_cycle(10,slice(5e-03))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn3.show_results()\nlearn3.save('model',return_path=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(f'Training Accuracy:{round(100*correct/total,2)}%')\n# # print(f'Validation Accuracy:{round(100*t_cor/t_tot,2)}%')\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nimport matplotlib.image as mpimg\n%matplotlib inline\nface_cascade = cv2.CascadeClassifier('/kaggle/input/detectors/haarcascade_frontalface_default.xml')\nimage = cv2.imread('/kaggle/input/tester/IMG-20171130-WA0012.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"faces = face_cascade.detectMultiScale(image, 1.2, 2)\nimage_with_detections = image.copy()\nfor (x,y,w,h) in faces:\n    cv2.rectangle(image_with_detections,(x,y),(x+w,y+h),(224,0,0),3) \n\nfig = plt.figure(figsize=(9,9))\n\nplt.imshow(image_with_detections)\nmod = learn3.model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mod.load_state_dict(torch.load('/tmp/models/model.pth'))\n\nimage_copy = np.copy(image)\natt = []\n# loop over the detected faces from your haar cascade\nfor idx,(x,y,w,h) in enumerate(faces):\n    # Select the region of interest that is the face in the image \n    roi = image_copy[y:y+h, x:x+w]\n    \n    ## TODO: Convert the face region from RGB to grayscale\n    roi = roi/255.0\n    ## TODO: Normalize the grayscale image so that its color range falls in [0,1] instead of [0,255]\n    ## TODO: Rescale the detected face to be the expected square size for your CNN (224x224, suggested)\n    h,w = roi.shape[:2]   \n    output_size = 224\n    if h>w:\n        new_h, new_w = output_size*h/w, output_size\n    else:\n        new_h, new_w = output_size, output_size*w/h\n    new_h, new_w = int(new_h), int(new_w)\n\n    img = cv2.resize(roi, (new_w, new_h))\n    \n\n    \n    ## TODO: Reshape the numpy image shape (H x W x C) into a torch image shape (C x H x W)\n    img = img.reshape(img.shape[0], img.shape[1], 3)\n    img = img.transpose((2, 0, 1))\n    img = torch.from_numpy(img)\n    img.unsqueeze_(0)\n    \n    ## TODO: Make facial keypoint predictions using your loaded, trained network \n    mod.eval()\n    mod = mod.double()\n    img = img.to(device)\n    out = mod(img)\n    out = out.cpu()\n    out = out.detach().numpy()\n    out = np.exp(out)\n    li = out.tolist()\n    ind = li[0].index(max(li[0]))\n    att.append(classesDict[ind])\n    print(classesDict[ind])\n    img = img.cpu()\n    img = img.reshape(224,224,3)\n    plt.imshow(np.squeeze(img))\n    plt.axis('off')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(att, columns=[\"attendees\"])\ndf.to_csv('list.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}